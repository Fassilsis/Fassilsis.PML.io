library(caret)
library(randomForest)
library(doParallel)
library(rattle)
library(rpart.plot)
library(corrplot)


##Acknowledgement

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har

Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6. 


##Load the data
{r cache=TRUE}
trng_url = "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv";
test_url = "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv";
training = read.csv(url(trng_url), header=TRUE, na.strings=c("NA","#DIV/0!",""));
testing  = read.csv(url(test_url), header=TRUE, na.strings=c("NA","#DIV/0!",""));


##View the training data. Uncomment some code if you need to view.
   {r results=FALSE, echo=FALSE}
##summary(training) # uncomment if you need to see this
##names(training)   # uncomment if you need to see this.
dim(training);
str(training);
##summary(training) # uncomment if you need to see this
##names(training)   # uncomment if you need to see this.
dim(testing);
str(testing);


##Clean up the data a bit.
 

    {r results = TRUE, cache = TRUE}
trng_cleaned = training[, -c(1:7)];
trng_cleaned = trng_cleaned[sapply(trng_cleaned,
                   function(x) {sum(is.na(x)) < (0.2 * nrow(trng_cleaned))})];
dim(trng_cleaned);


The training data after cleaning up has rows and  columns. 

Let's remove the first column from the test data. 

    {r results = TRUE, cache = TRUE}
test_cleaned = testing[, -1];
test_cleaned = test_cleaned[sapply(test_cleaned,
                   function(x) {sum(is.na(x)) < (0.2 * nrow(test_cleaned))})];


### Slice the training data into training and validation

    {r results = TRUE, cache = TRUE}
set.seed (1000) # For reproducibile results
in_train   = createDataPartition (trng_cleaned$classe, p = 0.70, list = FALSE)
train_partition  = trng_cleaned[in_train, ]
valid_partition  = trng_cleaned[-in_train, ]
    

## Train the Model on the training partition with **Random Forest** algorithm 

    {r results = TRUE, cache = TRUE}
trng_ctrl = trainControl (method = "cv", 5)
mdl_rf    = train (classe ~ ., data = train_partition,
                   method="rf", trControl = trng_ctrl)
mdl_rf
   

## Estimate the accuracy of the model on the validation partition.  

  {r results = TRUE, cache = TRUE}
pred_rf = predict (mdl_rf, valid_partition);
confusionMatrix (valid_partition$classe, pred_rf);
accuracy = postResample(pred_rf, valid_partition$classe);
accuracy;
out_of_samp_err = 1 - as.numeric(confusionMatrix(valid_partition$classe,
                                                 pred_rf)$overall[1]);
out_of_samp_err;
 

The estimated accuracy of the model is 99.42% and the estimated out-of-sample error is 0.58%.

## Apply the model to do prediction on the Test data 

    {r results = TRUE, cache = TRUE}
result = predict(mdl_rf, test_cleaned);
result;



###1. Accuracy of the Random Forest model  
    {r, cache = TRUE}
plot(mdl_rf, main="Accuracy of Random forest model by number of predictors");


###2. Decision Tree Visualization
    {r, cache = TRUE}
tree_mdl = rpart(classe ~ ., data=train_partition, method="class");
prp(tree_mdl);
